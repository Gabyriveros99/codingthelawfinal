{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yfpHevGkbqgn"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8a325bbb7e9b491db663e90f1c4bda5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1fe8391d573438d9cb9314f0d75ba99",
              "IPY_MODEL_22ca94eeda144b649d4dfb0ce640f8f2",
              "IPY_MODEL_731e7d8d8e0a44079fc4eba36e10a394"
            ],
            "layout": "IPY_MODEL_6f638ae7ef1d42889782cf8f92c2c6d6"
          }
        },
        "a1fe8391d573438d9cb9314f0d75ba99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6339d8d19db45dba9a1cb71b6e74a4d",
            "placeholder": "​",
            "style": "IPY_MODEL_55cc2dfde1e44874bc01e00247fee87c",
            "value": "(…)gingface.co/gpt2/resolve/main/vocab.json: 100%"
          }
        },
        "22ca94eeda144b649d4dfb0ce640f8f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_568905ed64ee466a876dc9d24099762d",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_377d1df2ecb34acf8852e05c94ac8bf0",
            "value": 1042301
          }
        },
        "731e7d8d8e0a44079fc4eba36e10a394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49a99f3edce3475fa089d0d27ee8b14a",
            "placeholder": "​",
            "style": "IPY_MODEL_bee75669fe51470fb1f2fcacaf04ccbf",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 4.47MB/s]"
          }
        },
        "6f638ae7ef1d42889782cf8f92c2c6d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6339d8d19db45dba9a1cb71b6e74a4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55cc2dfde1e44874bc01e00247fee87c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "568905ed64ee466a876dc9d24099762d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "377d1df2ecb34acf8852e05c94ac8bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49a99f3edce3475fa089d0d27ee8b14a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bee75669fe51470fb1f2fcacaf04ccbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a123b959d834e17bceda70b9dc19b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_419139c9ebba432eb61ea32f67b0e8f7",
              "IPY_MODEL_2dfcf8b96f144508bead93e3f4c91151",
              "IPY_MODEL_e48321803ebb42ad9a8cd89420915e98"
            ],
            "layout": "IPY_MODEL_bbfd6d49e6924b6a81cbd82aec350005"
          }
        },
        "419139c9ebba432eb61ea32f67b0e8f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e34e6657444a4281ab0741042027bcf6",
            "placeholder": "​",
            "style": "IPY_MODEL_bceceb1bf7124b608a172768777b1646",
            "value": "(…)gingface.co/gpt2/resolve/main/merges.txt: 100%"
          }
        },
        "2dfcf8b96f144508bead93e3f4c91151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d600360609e4cb39a9fa6cdb1ecc6f0",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_178092ab8037410d9f449e92c5585b69",
            "value": 456318
          }
        },
        "e48321803ebb42ad9a8cd89420915e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f77ef257ff5244c8a93789fd1eecdc17",
            "placeholder": "​",
            "style": "IPY_MODEL_7e96266c89774de3adaa923926285155",
            "value": " 456k/456k [00:00&lt;00:00, 4.88MB/s]"
          }
        },
        "bbfd6d49e6924b6a81cbd82aec350005": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e34e6657444a4281ab0741042027bcf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bceceb1bf7124b608a172768777b1646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d600360609e4cb39a9fa6cdb1ecc6f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "178092ab8037410d9f449e92c5585b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f77ef257ff5244c8a93789fd1eecdc17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e96266c89774de3adaa923926285155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3dc92f65fc442a8a2d90c6f9a39d9c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1572f591cd4d43b591196e87b5e304d2",
              "IPY_MODEL_408c6381a523414f8ce8b432196e2933",
              "IPY_MODEL_c029103cdd524b269a51921ff0fa39da"
            ],
            "layout": "IPY_MODEL_8153b1502ca046a1adc093d8822fecd0"
          }
        },
        "1572f591cd4d43b591196e87b5e304d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ac8c02f648a4bef8640d51bfe09e2ef",
            "placeholder": "​",
            "style": "IPY_MODEL_f2fd2bd65b07465db6b59edcdf3c644a",
            "value": "(…)face.co/gpt2/resolve/main/tokenizer.json: 100%"
          }
        },
        "408c6381a523414f8ce8b432196e2933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_024c3c2c18054ab4ac39cf74a630ad52",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35c83618395c45839d2a4be6672d9c2d",
            "value": 1355256
          }
        },
        "c029103cdd524b269a51921ff0fa39da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3139e44b4e4440f09f0041c554dce8ae",
            "placeholder": "​",
            "style": "IPY_MODEL_05e4016d2d674e289aa03cde7b193a67",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 9.96MB/s]"
          }
        },
        "8153b1502ca046a1adc093d8822fecd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ac8c02f648a4bef8640d51bfe09e2ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2fd2bd65b07465db6b59edcdf3c644a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "024c3c2c18054ab4ac39cf74a630ad52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35c83618395c45839d2a4be6672d9c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3139e44b4e4440f09f0041c554dce8ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05e4016d2d674e289aa03cde7b193a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a889255cf5114ea7b35cb52b8834b634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6872f8f12bcb4eefaf46eab37fc116bf",
              "IPY_MODEL_85aee0f1d6e34d64b4dae57bf614c84f",
              "IPY_MODEL_8e21817ac06340f3ab91f451a78ad3aa"
            ],
            "layout": "IPY_MODEL_bb009cc0e3014b19a3a8a5b76084a4d3"
          }
        },
        "6872f8f12bcb4eefaf46eab37fc116bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51b8a7b534254916895325ec2d2bc9bb",
            "placeholder": "​",
            "style": "IPY_MODEL_095f2da3deb84326bb7a24f1b89c27b2",
            "value": "(…)ingface.co/gpt2/resolve/main/config.json: 100%"
          }
        },
        "85aee0f1d6e34d64b4dae57bf614c84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5c664624eb24511a008006e3711a909",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_806adfea31a0438b8c0992d85324febd",
            "value": 665
          }
        },
        "8e21817ac06340f3ab91f451a78ad3aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3829fb3566e74a528d4bbd1c05e4399c",
            "placeholder": "​",
            "style": "IPY_MODEL_605d1984e2cc451bba3c9fe56b141aad",
            "value": " 665/665 [00:00&lt;00:00, 26.7kB/s]"
          }
        },
        "bb009cc0e3014b19a3a8a5b76084a4d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51b8a7b534254916895325ec2d2bc9bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "095f2da3deb84326bb7a24f1b89c27b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5c664624eb24511a008006e3711a909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "806adfea31a0438b8c0992d85324febd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3829fb3566e74a528d4bbd1c05e4399c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "605d1984e2cc451bba3c9fe56b141aad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gabyriveros99/codingthelawfinal/blob/main/Negotiation_Salary_CTL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Simple Text-Adventure Engine\n",
        "\n",
        "To play a game, run the cells below and follow the instructions under **Role Play**. If you're not intested in seeing any code code, simpily don't expand those sections. Note: you will need an OpenAI API key.\n",
        "\n"
      ],
      "metadata": {
        "id": "cBwaKSob1Stk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You'll need an API key to play. After creating an OpenAI account,\n",
        "# you can create an API key here: https://platform.openai.com/account/api-keys\n",
        "api_key = \"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\" #<---- Place your API key here!"
      ],
      "metadata": {
        "id": "kDVXF6FjLLuI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Stuff\n",
        "\n",
        "Will probably take around 50 seconds."
      ],
      "metadata": {
        "id": "NalKLyvrLdtz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packages\n",
        "This is the part that takes around 50 seconds."
      ],
      "metadata": {
        "id": "yfpHevGkbqgn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yLyBnrWCkYHC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8a325bbb7e9b491db663e90f1c4bda5d",
            "a1fe8391d573438d9cb9314f0d75ba99",
            "22ca94eeda144b649d4dfb0ce640f8f2",
            "731e7d8d8e0a44079fc4eba36e10a394",
            "6f638ae7ef1d42889782cf8f92c2c6d6",
            "c6339d8d19db45dba9a1cb71b6e74a4d",
            "55cc2dfde1e44874bc01e00247fee87c",
            "568905ed64ee466a876dc9d24099762d",
            "377d1df2ecb34acf8852e05c94ac8bf0",
            "49a99f3edce3475fa089d0d27ee8b14a",
            "bee75669fe51470fb1f2fcacaf04ccbf",
            "9a123b959d834e17bceda70b9dc19b9c",
            "419139c9ebba432eb61ea32f67b0e8f7",
            "2dfcf8b96f144508bead93e3f4c91151",
            "e48321803ebb42ad9a8cd89420915e98",
            "bbfd6d49e6924b6a81cbd82aec350005",
            "e34e6657444a4281ab0741042027bcf6",
            "bceceb1bf7124b608a172768777b1646",
            "1d600360609e4cb39a9fa6cdb1ecc6f0",
            "178092ab8037410d9f449e92c5585b69",
            "f77ef257ff5244c8a93789fd1eecdc17",
            "7e96266c89774de3adaa923926285155",
            "d3dc92f65fc442a8a2d90c6f9a39d9c8",
            "1572f591cd4d43b591196e87b5e304d2",
            "408c6381a523414f8ce8b432196e2933",
            "c029103cdd524b269a51921ff0fa39da",
            "8153b1502ca046a1adc093d8822fecd0",
            "4ac8c02f648a4bef8640d51bfe09e2ef",
            "f2fd2bd65b07465db6b59edcdf3c644a",
            "024c3c2c18054ab4ac39cf74a630ad52",
            "35c83618395c45839d2a4be6672d9c2d",
            "3139e44b4e4440f09f0041c554dce8ae",
            "05e4016d2d674e289aa03cde7b193a67",
            "a889255cf5114ea7b35cb52b8834b634",
            "6872f8f12bcb4eefaf46eab37fc116bf",
            "85aee0f1d6e34d64b4dae57bf614c84f",
            "8e21817ac06340f3ab91f451a78ad3aa",
            "bb009cc0e3014b19a3a8a5b76084a4d3",
            "51b8a7b534254916895325ec2d2bc9bb",
            "095f2da3deb84326bb7a24f1b89c27b2",
            "f5c664624eb24511a008006e3711a909",
            "806adfea31a0438b8c0992d85324febd",
            "3829fb3566e74a528d4bbd1c05e4399c",
            "605d1984e2cc451bba3c9fe56b141aad"
          ]
        },
        "outputId": "cef03b7c-337f-4205-aca4-ba7d3b05dba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.19.4 safetensors-0.4.0 tokenizers-0.15.0 transformers-4.35.2\n",
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.3.2\n",
            "    Uninstalling openai-1.3.2:\n",
            "      Successfully uninstalled openai-1.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "openai"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)gingface.co/gpt2/resolve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a325bbb7e9b491db663e90f1c4bda5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)gingface.co/gpt2/resolve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a123b959d834e17bceda70b9dc19b9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)face.co/gpt2/resolve/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3dc92f65fc442a8a2d90c6f9a39d9c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)ingface.co/gpt2/resolve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a889255cf5114ea7b35cb52b8834b634"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install transformers\n",
        "#!pip install openai\n",
        "!pip install openai==0.28\n",
        "!pip install tiktoken\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import random\n",
        "from datetime import date, datetime, timedelta\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "import openai\n",
        "from transformers import GPT2TokenizerFast\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
        "\n",
        "import tiktoken\n",
        "ENCODING = \"gpt2\"\n",
        "encoding = tiktoken.get_encoding(ENCODING)\n",
        "\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual, Layout\n",
        "import ipywidgets as widgets\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n",
        "\n",
        "openai.api_key = api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom functions"
      ],
      "metadata": {
        "id": "GQ3xktng1srO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_text(prompt,temp=0,trys=0,clean=False,tokens_used=0):\n",
        "\n",
        "    model=\"text-davinci-003\"\n",
        "    model_token_limit = 4097\n",
        "\n",
        "    token_count = len(encoding.encode(prompt))\n",
        "    max_tokens= model_token_limit-round(token_count+5)\n",
        "\n",
        "    #try:\n",
        "    response = openai.Completion.create(\n",
        "      model=model,\n",
        "      prompt=prompt,\n",
        "      temperature=temp,\n",
        "      max_tokens=max_tokens,\n",
        "      top_p=1.0,\n",
        "      frequency_penalty=0.0,\n",
        "      presence_penalty=0.0\n",
        "    )\n",
        "    output = str(response[\"choices\"][0][\"text\"].strip())\n",
        "    #except:\n",
        "        #print(\"Problem with API call!\")\n",
        "        #output = \"\"\"{\"output\":\"error\"}\"\"\"\n",
        "\n",
        "    tokens_used += token_count+len(encoding.encode(output))\n",
        "\n",
        "    if clean:\n",
        "        cleaned_output,tokens_used = clean_pseudo_json(output,temp=0,trys=trys,tokens_used=tokens_used)\n",
        "        try:\n",
        "            cleaned_output = json.loads(cleaned_output)\n",
        "        except:\n",
        "            cleaned_output = cleaned_output\n",
        "        return cleaned_output,tokens_used\n",
        "    else:\n",
        "        try:\n",
        "            output = json.loads(output)\n",
        "        except:\n",
        "            output = output\n",
        "        return output,tokens_used\n",
        "\n",
        "def clean_pseudo_json(string,temp=0,key=\"output\",trys=0,ask_for_help=1,tokens_used=0):\n",
        "    try:\n",
        "        output = json.loads(string)[key]\n",
        "    except:\n",
        "        try:\n",
        "            string_4_json = re.findall(\"\\{.*\\}\",re.sub(\"\\n\",\"\",string))[0]\n",
        "            output = json.loads(string_4_json)[key]\n",
        "        except:\n",
        "            try:\n",
        "                string = \"{\"+string+\"}\"\n",
        "                string_4_json = re.findall(\"\\{.*\\}\",re.sub(\"\\n\",\"\",string))[0]\n",
        "                output = json.loads(string_4_json)[key]\n",
        "            except Exception as e:\n",
        "                prompt = \"I tried to parse some json and got this error, '{}'. This was the would-be json.\\n\\n{}\\n\\nReformat it to fix the error.\".format(e,string)\n",
        "                if trys <= 3:\n",
        "                    if trys == 0:\n",
        "                        warm_up = 0\n",
        "                    else:\n",
        "                        warm_up = 0.25\n",
        "                    output,tokens_used = complete_text(prompt,temp=0+warm_up,trys=trys+1,tokens_used=tokens_used)\n",
        "                    print(\"\\n\"+str(output)+\"\\n\")\n",
        "                elif ask_for_help==1:\n",
        "                    print(prompt+\"\\nReformaing FAILED!!!\")\n",
        "                    try:\n",
        "                        os.system( \"say hey! I need some help. A little help please?\")\n",
        "                    except:\n",
        "                        print(\"'say' not supported.\\n\\n\")\n",
        "                    output = input(\"Let's see if we can avoid being derailed. Examine the above output and construct your own output text. Then enter it below. If the output needs to be something other than a string, e.g., a list or json, start it with `EVAL: `. If you're typing that, be very sure there's no malicious code in the output.\\n\")\n",
        "                    if output[:6]==\"EVAL: \":\n",
        "                        output = eval(output[6:])\n",
        "                else:\n",
        "                    output = \"There was an error getting a reponse!\"\n",
        "\n",
        "    return output,tokens_used\n"
      ],
      "metadata": {
        "id": "6jvCoNUSkvKa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4325368f-8574-4b13-91f6-9a00e9edbb9c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_dict(data, key, value):\n",
        "  \"\"\"Filter a list of dictionaries by a given key and value.\n",
        "\n",
        "  Args:\n",
        "    data: A list of dictionaries.\n",
        "    key: The key to filter by.\n",
        "    value: The value to filter by.\n",
        "\n",
        "  Returns:\n",
        "    A list of dictionaries that match the given key and value.\n",
        "  \"\"\"\n",
        "\n",
        "  filtered_data = []\n",
        "  for item in data:\n",
        "    if item[key] == value:\n",
        "      filtered_data.append(item)\n",
        "  return filtered_data[0]\n",
        "\n",
        "def find_other_dict(data, key, value):\n",
        "  \"\"\"Filter a list of dictionaries by a given key and value.\n",
        "\n",
        "  Args:\n",
        "    data: A list of dictionaries.\n",
        "    key: The key to filter by.\n",
        "    value: The value to filter by.\n",
        "\n",
        "  Returns:\n",
        "    A list of dictionaries that do NOT match the given key and value.\n",
        "  \"\"\"\n",
        "\n",
        "  filtered_data = []\n",
        "  for item in data:\n",
        "    if item[key] != value:\n",
        "      filtered_data.append(item)\n",
        "  return random.choice(filtered_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "tclevXkbgm5R",
        "outputId": "daf44083-467d-4506-e3cc-f013b0a53b13"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_scene(state):\n",
        "\n",
        "  if state[\"scene\"]>0:\n",
        "    last = \"\\n\\nFor context, in the last scene this is what happened: {}\".format(state[\"scenes\"][state[\"scene\"]-1][\"summary\"])\n",
        "  else:\n",
        "    last = \"\"\n",
        "\n",
        "  prompt = \"\"\"Given the following information, write a short bit of prose establishing the scene. Use super descriptive language. Paint a picture with your words. {}\n",
        "\n",
        "Background for this scene:\n",
        "{}{}\n",
        "\n",
        "Return a json object, including the outermost currly brakets, where the key is \"output\" and the value is the text of your prose. Be sure to use valid json, encasing keys and values in double quotes, and escaping internal quotes and special characters as needed.\n",
        "\"\"\".format(last,state[\"genre\"],state[\"scenes\"][state[\"scene\"]][\"setting\"])\n",
        "\n",
        "  #print(\"\\n\"+prompt+\"\\n\")\n",
        "\n",
        "  return \"Narrator: \"+complete_text(prompt,temp=0.7)[0][\"output\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wv9tZLHAMuWL",
        "outputId": "e490631a-16c8-433e-9f46-958b06165186"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_line(state, auto=0):\n",
        "\n",
        "  possible_roles = []\n",
        "  for name in state[\"scenes\"][state[\"scene\"]][\"present\"]:\n",
        "    possible_roles += [find_dict(state[\"characters\"], \"name\", name)]\n",
        "\n",
        "  if auto==0:\n",
        "    state[\"scenes\"][state[\"scene\"]][\"transcript\"] += [\"{}: {}\".format(state[\"play_as\"],state[\"input\"])]\n",
        "    role = find_other_dict(possible_roles, \"name\", state[\"play_as\"])\n",
        "  elif auto==1:\n",
        "    #print(\"Auto generating line for {}.\".format(state[\"play_as\"]))\n",
        "    role = find_dict(possible_roles, \"name\", state[\"play_as\"])\n",
        "\n",
        "  prompt = \"\"\"{}{} You are an actor playing the role of {}. {}{}\n",
        "\n",
        "{}\n",
        "\n",
        "Acording to the director: {}\n",
        "\n",
        "Here is a transcript of what has happened so far, with the Narrator providing insight into physical actions.\n",
        "\n",
        "{}\n",
        "\n",
        "--\n",
        "\n",
        "In character, how do you respond? Do not repeat yourself.\n",
        "\n",
        "Return a json object, including the outermost currly brakets, where the key is \"output\" and the value is the text of your response as it would appear on a script, be sure to start with \"{}:\". Be sure to use valid json, encasing keys and values in double quotes, and escaping internal quotes and special characters as needed.\n",
        "\"\"\".format(state[\"genre\"],state[\"scenes\"][state[\"scene\"]][\"setting\"],role[\"name\"],role[\"brief_bio\"],role[\"motivation\"],state[\"scenes\"][state[\"scene\"]][\"frame\"],state[\"scenes\"][state[\"scene\"]][\"directors_notes\"],\"\\n\".join(state[\"scenes\"][state[\"scene\"]][\"transcript\"]),role[\"name\"])\n",
        "\n",
        "  #print(\"\\n\\n\"+prompt+\"\\n\\n\")\n",
        "\n",
        "  return complete_text(prompt,temp=0.7)[0][\"output\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "309mTs16o-B5",
        "outputId": "ba9438a9-ae18-4431-c5cc-3a251d2734e4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_direction(state):\n",
        "\n",
        "  prompt = \"\"\"{}{} Here is a transcript of what has happened so far, with the Narrator providing insight into physical actions.\n",
        "\n",
        "{}\n",
        "\n",
        "----\n",
        "\n",
        "{} would like to {}.\n",
        "\n",
        "Based on what you know of the situation, return a narrator's description of what should happen next in the story. Do not include dialogue, only narration.\n",
        "\n",
        "Use super descriptive language. Paint a picture with your words.\n",
        "\n",
        "Return a json object, including the outermost currly brakets, where the key is \"output\" and the value is the text of your response. Be sure to use valid json, encasing keys and values in double quotes, and escaping internal quotes and special characters as needed.\n",
        "\"\"\".format(state[\"genre\"],state[\"scenes\"][state[\"scene\"]][\"setting\"],\"\\n\".join(state[\"scenes\"][state[\"scene\"]][\"transcript\"]),state[\"play_as\"],re.findall(\"^do: ?(.*)\",state[\"input\"])[0])\n",
        "\n",
        "  #print(\"\\n\"+prompt+\"\\n\")\n",
        "\n",
        "  return \"Narrator: \"+complete_text(prompt,temp=0.7)[0][\"output\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "turhce1bo-Jb",
        "outputId": "b18adc36-feee-41cf-801c-72a280b093ed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_up(state):\n",
        "\n",
        "  prompt = \"\"\"{} Here is a transcript of what has happened so far, with the Narrator providing insight into physical actions.\n",
        "\n",
        "Transcript:\n",
        "\n",
        "{}\n",
        "\n",
        "-----\n",
        "{} Write a short summary of what has happened so far, being sure to note who has done what.\n",
        "\n",
        "Return a json object, including the outermost currly brakets, where the key is \"output\" and the value is your summary. Be sure to use valid json, encasing keys and values in double quotes, and escaping internal quotes and special characters as needed.\n",
        "\"\"\".format(state[\"scenes\"][state[\"scene\"]][\"setting\"],\"\\n\".join(state[\"scenes\"][state[\"scene\"]][\"transcript\"]),state[\"scenes\"][state[\"scene\"]][\"ends_when\"])\n",
        "\n",
        "  #print(\"\\n\"+prompt+\"\\n\")\n",
        "\n",
        "  return complete_text(prompt,temp=0.7)[0][\"output\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "bVJ9mXse6nEs",
        "outputId": "fb467c5a-381b-4d65-88fc-46539fa15d4e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def end_scene(state):\n",
        "\n",
        "  prompt = \"\"\"{} Here is a transcript of what has happened so far, with the Narrator providing insight into physical actions.\n",
        "\n",
        "Transcript:\n",
        "\n",
        "{}\n",
        "\n",
        "-----\n",
        "{} Has this happened yet, yes or no?\n",
        "\n",
        "Return a json object, including the outermost currly brakets, where the key is \"output\" and the value is \"yes\" or \"no.\" Be sure to use valid json, encasing keys and values in double quotes, and escaping internal quotes and special characters as needed.\n",
        "\"\"\".format(state[\"scenes\"][state[\"scene\"]][\"setting\"],\"\\n\".join(state[\"scenes\"][state[\"scene\"]][\"transcript\"]),state[\"scenes\"][state[\"scene\"]][\"ends_when\"])\n",
        "\n",
        "  #print(\"\\n\"+prompt+\"\\n\")\n",
        "\n",
        "  response = complete_text(prompt,temp=0.7)[0][\"output\"]\n",
        "  if \"yes\" in response.lower():\n",
        "\n",
        "    state[\"scenes\"][state[\"scene\"]][\"summary\"] = sum_up(state)\n",
        "\n",
        "    if state[\"scene\"]<len(state[\"scenes\"])-1:\n",
        "      print(\"New scene!\\n\")\n",
        "      state[\"scene\"] += 1\n",
        "      output = set_scene(state)\n",
        "      state[\"scenes\"][state[\"scene\"]][\"transcript\"] += [output]\n",
        "\n",
        "      if state[\"player_goes_first\"] == 0:\n",
        "        print(\"Auto generate first line\")\n",
        "        user_tmp = state[\"play_as\"]\n",
        "        possible_roles = []\n",
        "        for name in state[\"scenes\"][state[\"scene\"]][\"present\"]:\n",
        "          possible_roles += [find_dict(state[\"characters\"], \"name\", name)]\n",
        "        state[\"play_as\"] = find_other_dict(possible_roles, \"name\", state[\"play_as\"])[\"name\"]\n",
        "        output = new_line(state,1)\n",
        "        state[\"play_as\"] = user_tmp\n",
        "        state[\"scenes\"][state[\"scene\"]][\"transcript\"] += [output]\n",
        "        next = end_scene(state)\n",
        "\n",
        "    else:\n",
        "      print(\"The End\\n\")\n",
        "      state[\"scene\"] = -1\n",
        "\n",
        "  return state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lN-NfVkW7-76",
        "outputId": "ac336e68-f817-4f82-fff9-b32752d1bc36"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_names(state):\n",
        "  names = []\n",
        "  for name in state[\"characters\"]:\n",
        "    names += [name[\"name\"]]\n",
        "  return names\n",
        "\n",
        "def run_scene (state):\n",
        "\n",
        "  scene_index = int(state[\"scene\"])\n",
        "  if len(state[\"scenes\"][scene_index][\"transcript\"]) == 0:\n",
        "    output = set_scene(state)\n",
        "    state[\"scenes\"][scene_index][\"transcript\"] += [output]\n",
        "\n",
        "\n",
        "    if state[\"player_goes_first\"] == 0:\n",
        "      print(\"Auto generate first line\")\n",
        "      user_tmp = state[\"play_as\"]\n",
        "      possible_roles = []\n",
        "      for name in state[\"scenes\"][state[\"scene\"]][\"present\"]:\n",
        "        possible_roles += [find_dict(state[\"characters\"], \"name\", name)]\n",
        "      state[\"play_as\"] = find_other_dict(possible_roles, \"name\", state[\"play_as\"])[\"name\"]\n",
        "      output = new_line(state,1)\n",
        "      state[\"play_as\"] = user_tmp\n",
        "      state[\"scenes\"][state[\"scene\"]][\"transcript\"] += [output]\n",
        "      next = end_scene(state)\n",
        "\n",
        "  else:\n",
        "    if state[\"input\"]!=\"\":\n",
        "      if re.findall(\"^do: ?(.*)\",state[\"input\"]):\n",
        "        output = new_direction(state)\n",
        "      else:\n",
        "        output = new_line(state)\n",
        "\n",
        "      state[\"scenes\"][state[\"scene\"]][\"transcript\"] += [output]\n",
        "      next = end_scene(state)\n",
        "    else:\n",
        "      print(\"Auto generate exchange\")\n",
        "      output = new_line(state,1)\n",
        "      possible_speaker = re.search(\"(\\w+):\",output)\n",
        "      if (possible_speaker):\n",
        "        if (possible_speaker[1] in get_names(state)):\n",
        "          output = re.sub(\"\\w+:\",\"\",output)\n",
        "      state[\"input\"] += output\n",
        "      state = run_scene(state)\n",
        "\n",
        "  state[\"input\"] = None\n",
        "\n",
        "  return state"
      ],
      "metadata": {
        "id": "W2nG2nTBk9g2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "99d7d0a3-b24d-404b-bf19-7974d5e3edda"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def role_paly(state):\n",
        "  global i, usr_output\n",
        "  if i>0:\n",
        "    state[\"input\"] = usr_output.value\n",
        "  i += 1\n",
        "\n",
        "  state = run_scene(state)\n",
        "\n",
        "  if state[\"scene\"]>=0:\n",
        "\n",
        "    print(\"\\nYou're name is {}. You are standing in... \\n\\n{}{}\\n\".format(state[\"play_as\"],state[\"scenes\"][state[\"scene\"]][\"setting\"],state[\"scenes\"][state[\"scene\"]][\"frame\"]))\n",
        "\n",
        "    print(\"Note: {}\\n\".format(state[\"scenes\"][state[\"scene\"]][\"ends_when\"]))\n",
        "\n",
        "    print(\"What do you do/say?\\n\")\n",
        "\n",
        "    script = widgets.Textarea(\n",
        "      value=\"\\n\\n\".join(state[\"scenes\"][state[\"scene\"]][\"transcript\"]),\n",
        "      description='Trascript:',\n",
        "      disabled=True,\n",
        "      layout=Layout(width='95%', height='300px')\n",
        "    )\n",
        "    display(script)\n",
        "\n",
        "    usr_output = widgets.Textarea(\n",
        "        value=\"\",\n",
        "        description='Say/Do:',\n",
        "        disabled=False,\n",
        "        layout=Layout(width='95%', height='50px')\n",
        "    )\n",
        "\n",
        "    display(usr_output)\n",
        "  else:\n",
        "    j = 1\n",
        "    for scene in state[\"scenes\"]:\n",
        "      print(\"=============\\n\\nSCENE {}\\n\".format(j))\n",
        "      print(\"\\n\\n\".join(state[\"scenes\"][state[\"scene\"]][\"transcript\"]))\n",
        "      j+=1\n",
        "    print(\"\\n\\n~ THE END ~\")"
      ],
      "metadata": {
        "id": "I-RaPQh6mwf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ff3751b9-53df-4c14-a09e-0077433083ba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rewrite(state,temp):\n",
        "\n",
        "  text = \"\"\n",
        "  j = 1\n",
        "  for scene in state[\"scenes\"]:\n",
        "    if len(state[\"scenes\"][j-1][\"transcript\"])>0:\n",
        "      text +=  \"\\n\\n===\\n\\nSCENE {}\\n\\n\".format(j)\n",
        "      prompt = \"\"\"Produce a novelization of the following transcript. That is, rewrite it to be a combination of prose and dialog, turning any narration into prose.\n",
        "\n",
        "Transcript:\n",
        "{}\n",
        "\n",
        "\"\"\".format(\"\\n\".join(state[\"scenes\"][j-1][\"transcript\"]))\n",
        "\n",
        "      #print(\"\\n\"+prompt+\"\\n\")\n",
        "      text += complete_text(prompt,temp=temp)[0]\n",
        "    j+=1\n",
        "\n",
        "  text +=  \"\\n\\n===\\n\\nTHE END\\n\\n\"\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "JPfqWfSK4SDf",
        "outputId": "f8c0e04f-9693-4491-e638-3704a17b6a77"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define your world\n",
        "\n",
        "The `state` dictionary contains the information we use to help set the scene. Unless you want to keep playing the default world, you'll need to edit this dictionary. That is, to create a world of your own just edit the text in the cell below."
      ],
      "metadata": {
        "id": "xlPkA_Vv20wV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the stage for an interactive text adventure\n",
        "state = {\n",
        "    \"genre\": \"The following scene takes place on a zoom call sometime in the near future. \", # Set expecations. Is this the real world or fantasy?\n",
        "    \"characters\": [\n",
        "                    # Add a dictionary for each player. They should include their `name`, a very short `brief_bio`, and `motivation` (what makes them tick).\n",
        "                    # adapted from this ChatGPt convo. See https://chat.openai.com/share/fc299da6-623b-4390-a584-a5241b7e34cc Teachable moment: What/Who's missing?\n",
        "                    {\n",
        "                        \"name\": \"Hiring Manager\",\n",
        "                        \"brief_bio\": \"The Hiring Manager is the general office manager of a small real estate law firm. He's worked in corporate settings before and is professional,he's friendly overall but is a tough negotiator when it comes to salaries.\",\n",
        "                        \"motivation\": \"Hiring Manager is open to negotiating but does want the final number to be as close to the original number as possible.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"name\": \"Young Attorney\",\n",
        "                        \"brief_bio\": \"Young Attorney is in 3rd year of law school. They are friendly but have an unexpected ferocity when it comes to their salary and negotiations. They are professional.\",\n",
        "                        \"motivation\": \"Young Attorney wants to get the highest number possible for theirsalary as they have to pay an unreal amount in student loans.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"name\": \"Partner\",\n",
        "                        \"brief_bio\": \"Partner has worked at this law firm for 15 years and is well known in the city as one of the best Real Estate attorneys. They are what is known as an old school attorney and does not want to give the Young Attorney all of their wishes in their job offer becaus they believe that attonreys have to work their way up just like he did when he became an associate. He is angry, not friendly and a hard bargainer.\",\n",
        "                        \"motivation\": \"Partner is not open to negotiating and believes the first offer they gave the Young Attorney was too much and that they didn't deserve it. He doesn't want to pay one mroe penny than the initial offer.\"\n",
        "                    },\n",
        "\n",
        "\n",
        "                ],\n",
        "    \"scenes\": [\n",
        "          {\n",
        "              \"present\" : [\"Hiring Manager\",\"Young Attorney\",\"Partner\"],\n",
        "              \"setting\": \"A zoom call with the Young Attorney, Partner and the Hiring Manager \", # Tell us where we are and what it looks like\n",
        "              \"frame\": \"The Hiring Manager and the Young Attorney have scheduled a zoom call to discuss the offer that the law firm offered the attorney two weeks ago. Partner is harsh and hesitant to give more leeway on the offer.\",\n",
        "              \"directors_notes\" : \"By the end of this scene the Hiring Manager, Partner, the Young Attorney should have completed their negotiations. \",\n",
        "              \"ends_when\": \"The scene ends after Young Attorney says, \\\"Thank you very much.\\\" \",\n",
        "              \"target_words\" : None,\n",
        "              \"transcript\": [], # Leave as is\n",
        "              \"summary\": \"\" # Leave as is\n",
        "          },\n",
        "\n",
        "#In this case, the negotiator, Young Attorney, is leading the call to try and get a higher salary offer. , # Explain why we're here\n",
        "           ]\n",
        "          ,\n",
        "  \"scene\": 0, # Starts at 0\n",
        "  \"play_as\": \"Young Attorney\", # Leave as is\n",
        "  \"player_goes_first\" : 1, # 1 if yes, 0 if no\n",
        "  \"input\": None # Leave as is\n",
        "}\n",
        "\n",
        "# Decide who the user will play as.\n",
        "#state[\"play_as\"] = \"Hiring Manager\" # define a specific character\n",
        "#state[\"play_as\"] = random.choice(state[\"characters\"])[\"name\"] # Choose a random character\n",
        "\n",
        "i = 0;\n",
        "try:\n",
        "    del usr_output\n",
        "except NameError:\n",
        "    pass"
      ],
      "metadata": {
        "id": "SJ0auZ0jm29V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "dce148cc-c311-4b1c-a2ba-d1367cecb114"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Role Play\n",
        "\n",
        "Use \"Say/Do\" to type what you would like to say or do. When not typing dialogue, start your input with the lowercase word \"do\" followed by a colon (i.e., \"do:\"). Also, you need to run the next cell after every entry.\n",
        "\n",
        "Note: Leaving \"Say/Do\" empty will cause the story to advance without your input (i.e., the LLM will take over game play)."
      ],
      "metadata": {
        "id": "lJOoSf0i11Us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "role_paly(state)"
      ],
      "metadata": {
        "id": "o_GmvZ49vKyy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 912
        },
        "outputId": "44b45031-31c9-4b7d-c9ee-a40a73fab91c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "APIRemovedInV1",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e474d5853511>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrole_paly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-27d5d75f3ba1>\u001b[0m in \u001b[0;36mrole_paly\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_scene\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scene\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-6b20bd8af833>\u001b[0m in \u001b[0;36mrun_scene\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mscene_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scene\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scenes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscene_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"transcript\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_scene\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scenes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscene_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"transcript\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-bf43a37dd3a4>\u001b[0m in \u001b[0;36mset_scene\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;31m#print(\"\\n\"+prompt+\"\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"Narrator: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcomplete_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-c0f313ff72c5>\u001b[0m in \u001b[0;36mcomplete_text\u001b[0;34m(prompt, temp, trys, clean, tokens_used)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     response = openai.Completion.create(\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_proxy.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_proxy.py\u001b[0m in \u001b[0;36m__get_proxied__\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/lib/_old_api.py\u001b[0m in \u001b[0;36m__load__\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(json.dumps(state,indent=4))"
      ],
      "metadata": {
        "id": "SXOfGfF5hdmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall openai\n",
        "!pip install openai==0.28\n",
        "\n",
        "import openai\n",
        "\n",
        "# Set your OpenAI GPT-3 API key\n",
        "openai.api_key = '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'\n",
        "\n",
        "def get_salary_negotiation_advice(state):\n",
        "    # Define the prompt for the GPT-3 model\n",
        "    prompt = f\"Provide advice and pointers for improving the following salary negotiation transcript:\\n\\n{state}\\n\\nAdvice:\"\n",
        "\n",
        "    # Call the OpenAI GPT-3 API\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",  # You can experiment with other engines\n",
        "        prompt=prompt,\n",
        "        max_tokens=200,  # Adjust based on the desired response length\n",
        "        temperature=0.7,  # Adjust for creativity vs. consistency\n",
        "        n=1,  # Number of completions to generate\n",
        "        stop=None,  # You can add custom stop words\n",
        "    )\n",
        "\n",
        "    # Extract and return the generated advice\n",
        "    advice = response['choices'][0]['text'].strip()\n",
        "    return advice\n",
        "\n",
        "# Define your role_play function\n",
        "def role_play(state):\n",
        "    # Your role_play function logic here\n",
        "    # For example:\n",
        "    result = f\"The role play result for the state:\\n\\n{state}\\n\\nis: [result_description_here]\"\n",
        "    return result\n",
        "\n",
        "# Example usage:\n",
        "state_transcript = \"I am negotiating my salary, and I would like to request a higher compensation because...\"\n",
        "role_play_result = role_play(state_transcript)\n",
        "\n",
        "# Get advice based on the role play result\n",
        "advice_result = get_salary_negotiation_advice(role_play_result)\n",
        "\n",
        "print(\"Role Play Result:\")\n",
        "print(role_play_result)\n",
        "\n",
        "print(\"\\nGenerated Advice:\")\n",
        "print(advice_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wQU2qpdpqP68",
        "outputId": "60a3db85-d23f-45c1-d6cb-04aad2dd7d9a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: openai 0.28.0\n",
            "Uninstalling openai-0.28.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/openai\n",
            "    /usr/local/lib/python3.10/dist-packages/openai-0.28.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/openai/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled openai-0.28.0\n",
            "Collecting openai==0.28\n",
            "  Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "openai"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "APIRemovedInV1",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-2bb831706e42>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Get advice based on the role play result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0madvice_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_salary_negotiation_advice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrole_play_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Role Play Result:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-2bb831706e42>\u001b[0m in \u001b[0;36mget_salary_negotiation_advice\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Call the OpenAI GPT-3 API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     response = openai.Completion.create(\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-davinci-003\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# You can experiment with other engines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_proxy.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_proxy.py\u001b[0m in \u001b[0;36m__get_proxied__\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/lib/_old_api.py\u001b[0m in \u001b[0;36m__load__\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Turn your adventure into a story\n",
        "\n",
        "Run the cell below to create a story based on your adventure."
      ],
      "metadata": {
        "id": "oE5PIW1AcqPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "story = rewrite(state,temp=0.45)\n",
        "print(story)"
      ],
      "metadata": {
        "id": "j6te80tr4cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "8644d8dc-bf56-4b75-8a2c-5f7787cb348c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "===\n",
            "\n",
            "SCENE 1\n",
            "\n",
            "The Young Attorney sat back in their chair, illuminated by the computer monitor's light. They listened intently as the Partner and Hiring Manager spoke, their crisp voices ebbing and flowing through the Zoom call. A sense of anticipation filled the air as the two parties discussed the potential of the Attorney joining their team. The silence seemed to linger, as if the next few words held the fate of the Attorney's career in the balance.\n",
            "\n",
            "Finally, the Young Attorney spoke up. \"Hi Partner and Hiring Manager, how are you? Thank you for taking this call.\"\n",
            "\n",
            "\"Hi there! We're doing well, and glad to have the opportunity to talk with you,\" the Hiring Manager replied. \"Let's get started, shall we?\"\n",
            "\n",
            "===\n",
            "\n",
            "THE END\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}